---
title: "Heart Attact"
author: "Tymoteusz Romanowicz, Patryk Tokarski"
format: html
editor: visual
embed-resources: true
execute: 
  warning: false
editor_options: 
  chunk_output_type: console
---

## Źródło danych

### Zawartość zbioru:

Dane do zbioru były zbierane podczas transportu karetką do szpitala pacjentów, którzy podejrzewali u siebie obecność zawału serca. Zawał mięśnia sercowego, potocznie zwany atakiem serca to martwica mięśnia sercowego spowodowana jego niedokrwieniem wskutek zamknięcia tętnicy wieńcowej doprowadzającej krew do serca. W Europie choroby układu krążenia są najczęstszą przyczyną zgonów. Z powodu schorzeń sercowo-naczyniowych w tym zawału mięśnia sercowego, umiera dwa razy więcej osób niż z powodu chorób nowotworowych. Zbiór danych zawiera 1319 obserwacji i 9 cech, z czego jedna odnosi się do obecności ataku serca.

Wiek, płeć, tętno, skurczowe ciśnienie tętnicze, rozkurczowe ciśnienie tętnicze, poziom cukru we krwi, CK-MB (kineaza kreatynowa) i troponina reprezentują pola wejściowe, podczas gdy pole wyjściowe odnosi się do obecności zawału serca, który jest podzielone na dwie kategorie (0 i 1); "0" odnosi się do braku zawału serca, podczas gdy "1" odnosi się do obecności zawału serca.

### Przedstawienie zmiennych: opis jakie są i co znaczą

| Cecha                    | Opis                                                                                                           |
|---------------------|---------------------------------------------------|
| Age                      | Wiek pacjenta w latach                                                                                         |
| Gender                   | Płeć pacjenta (0 - kobieta, 1 - mężczyzna)                                                                     |
| Heart Rate               | Maksymalne osiągnięte tętno (za prawidłowe tętno uznaje się przedział od 60 do 100 uderzeń serca na minutę)    |
| Systolic blood pressure  | Spoczynkowe skurczowe ciśnienie krwi (w mmHg, podczas dojazdu do szpitala) (normalne wartości 90-120 mmHg)     |
| Diastolic blood pressure | Spoczynkowe rozkurczowe ciśnienie krwi (w mmHg, podczas dojazdu do szpitala) (normalne wartości od 60-80 mmHg) |
| Blood sugar              | Poziom cukru we krwi (normalne wartości do 140mg/dl)                                                           |
| CK-MB                    | Enzym CK-MB (mężczyźni do 7,8 ng/mL, kobiety do 4,4 ng/mL). Jest to enzym kinazy kreatynowej.                  |
| Troponin                 | Enzym troponiny (wartości normalne do 0,03 mikrogramów)                                                        |
| Result                   | Obecność zawału (0 - brak zawału, 1 - zawał)                                                                   |

: Cechy i ich opisy

## Cele badawcze

-   Opracowanie modelu predykcyjnego, który na podstawie danych o pacjencie (wiek, płeć, tętno, ciśnienie krwi, poziom cukru we krwi, CK-MB, troponina), przewiduje czy miał on zawał serca.

-   Dokonanie segmentacji pacjentów, aby zidentyfikować grupy pacjentów o podobnym ryzyku wystąpienia zawału serca.

-   Używając technik wizualizacji danych wykryć wzorce i nietypowe zachowania w zbiorze danych, a także lepiej zrozumieć rozkłady poszczególnych zmiennych.

## Przygotowanie zbioru / weryfikacja poprawnosci danych / brakujace wartosci

```{r, echo=FALSE}
library(tidyverse)
library(foreign)
library(tidyverse)
library(plotly)
library(corrplot)
library(knitr)
library(PerformanceAnalytics)
library(pander)
library(rstatix)
library(GGally)
library(rstatix)
library(DALEX)
library(foreign)
library(dplyr)
library(caret)
library(rpart)
library(rattle)
```

```{r}
# wczytanie zbioru
df <- read.arff("data/Medicaldataset.arff")
df <- df %>% rename(
  "Age" = age,
  "Gender" = gender,
  "Heart Rate" = impluse,
  "Systolic.blood.pressure" = pressurehight,
  "Diastolic.blood.pressure" = pressurelow,
  "Blood.sugar" = glucose,
  "CK.MB" = kcm,
  "Troponin" = troponin,
  "Result" = class
)
```

```{r}
identify_outliers(df['Heart Rate']) %>% 
  as.data.frame() %>% 
  filter(is.extreme == TRUE) %>% 
  kable()
```

Występują trzy obserwacje, w których tętno wynosi 1111. Normalne tętno wynosi maksymalnie 100 uderzeń serca na minutę więc są to nieprawidłowe dane, najprawdopodobniej spowodowane błędem przy wpisywaniu danych, które należy usunąć.

```{r}
#czyszczenie zbioru, zamiana wartosci na factor
df <- df[df$`Heart Rate` != 1111, ]

df$Result <- ifelse(df$Result == "positive", 1, 0)

df$Gender <- as.factor(df$Gender)
df$Result <- as.factor(df$Result)
```

## Opis zbioru

Cechy jakościowe:

```{r}

df2 <- df %>% select(Result, Gender)
levels(df2$Result) <- c("Positive", "Negative")
levels(df2$Gender) <- c("Female", "Male")
df2 %>% summary() %>% pander()
```

Cechy ilościowe:

```{r}
df %>% get_summary_stats(show = c("min", "median","mean", "sd", "max")) %>% select(-n) %>%  pander()
```

## Wizualizacja

Piramida wieku

```{r}
df_sum <- df %>% 
  group_by(Age, Gender) %>% 
  summarise(count = n()) %>% 
  ungroup()

df_sum$neg_count <- ifelse(df_sum$Gender == 0, -df_sum$count, df_sum$count)
df_sum

# Group data into 5-year intervals
df_sum$AgeGroup <- cut(df_sum$Age, breaks = seq(0, max(df_sum$Age) + 5, by = 5), labels = FALSE)

# Summarize data within age intervals
df_smooth <- df_sum %>%
  group_by(AgeGroup, Gender) %>%
  summarise(sum_neg_count = sum(neg_count))

ggplot(df_smooth, aes(x = AgeGroup, y = sum_neg_count, fill = factor(Gender))) + 
  geom_bar(stat = "identity", position = "identity") + 
  scale_y_continuous(labels = abs, breaks = seq(-max(df_sum$count), max(df_sum$count), by = 1000)) + 
  labs(x = "Wiek", y = "Liczba") + 
  scale_fill_manual(values = c("0" = "#f8766d", "1" = "#00bfc4")) + 
  theme_minimal() + coord_flip() + guides(fill = "none")

# todo: zrobić ładniej 
```

Histogram wieku z podziałem na płeć oraz obecność ataku serca. Wyraźnie widać, że rozkład mężczyzn z atakiem serca (lewy dolny histogram) przypomina rozkład normalny. Natomiast pozostałe 3 wykresy są do siebie podobne i także przypominają rozkład normalny, tylko z o wiele mniejszą kurtozą.

```{r}
age_distr <- df %>% 
  mutate(Gender2 = ifelse(Gender == "0", "female", "male")) %>% 
  mutate(Result2 = ifelse(Result == "0", "negative", "positive"))

ggplot(age_distr, aes(x = Age, fill = Gender2)) +
  geom_histogram(binwidth = 5, color = "black", boundary=1) +
    scale_x_continuous(breaks = seq(0, 100, by = 10)) +
  facet_grid(Gender2 ~ Result2) +
  labs(title = "Age Distribution by Gender and Result", x = "Age", y = "Frequency") + guides(fill = "none")
```

Test proporcji dla obecności ataku serca ze względu na płeć. Hipoteza zerowa zakłada, że procent pozytywnych przypadków ataku serca jest taki sam dla obu płci. Hipoteza alternatywna zakłada, że procent pozytywnych przypadków ataku serca jest różny dla obu płci.

```{r}
# Tworzenie tablicy przestawnej
table <- table(df$Gender, df$Result)

# Przeprowadzenie testu proporcji (z testem chi-kwadrat)
result_prop_test <- prop.test(table)
chi_square_test <- chisq.test(table)

data.frame("Proportion test"=round(result_prop_test$p.value,3),
           "Chi-Square test"=round(chi_square_test$p.value,3)) %>% pander()
```

Na podstawie testu chi-kwadrat jak i test proporcjonalności odrzucamy hipotezę o rowności procenta pozytywnych przypadków ataku serca ze względu na płeć. Wynika z tego, że większą szansę na atak serca mają mężczyźni.

```{r}
#distibution of heart disease
df %>% ggplot(aes(x = Result, fill=Gender, )) +
  geom_bar(position = "dodge2") +
  labs(title = "Distribution of Heart Disease", x = "Result", y = "Frequency")+
  scale_fill_discrete(labels=c("Female", "Male"))
```

```{r}
chart.Correlation(df[,c(1,3:8)])
```

```{r}
df %>% 
  pivot_longer(cols = c(1, 3, 4, 5, 6, 7, 8), names_to = "variable", values_to = "value") %>% 
  ggplot(aes(x = value, fill = Result)) +
  geom_histogram(bins = 10, color = "black", alpha = 1) +
  facet_wrap(~variable, scales = "free") +
  labs(title = "Distribution of Variables by Result", x = "Value", y = "Frequency") +
  scale_fill_discrete(labels=c("Negative", "Positive"))
```

### Wykres zależności CK.MB od Troponiny z podziałem na pacjentów z zawałem i bez

```{r}
p <- ggplot(df, aes(x = CK.MB, y = Troponin, col = factor(Result))) + geom_point(alpha = 0.5) + scale_color_manual(values = c("1" = "red", "0" = "blue")) + labs(x = "CK.MB", y = "Troponin", col = "Result") + theme_minimal() + scale_y_log10() + scale_x_log10()

ggplotly(p)
```

## Model

### Wybór modelu - wypisac ktory moze byc najlepszy

-   wypisać jakich modeli próbowaliśmy użyć
-   wypisać jakie parametry mieliśmy do dyspozycji
-   wypisać jakie parametry wybraliśmy i dlaczego
-   wypisać jakie parametry odrzuciliśmy i dlaczego
-   wypisać jakie parametry byłyby przydatne, gdybyśmy były w zbiorze

### stworzenie modelu

-   kod dot. stworzenia modelu drzewa decyzyjnego

### trening modelu

### testowanie modelu

### Podsumowanie efektywności modelu / jego przydatności

-   apropo ad3 - Używając technik wizualizacji danych wykryć wzorce i nietypowe zachowania w zbiorze danych, a także lepiej zrozumieć rozkłady poszczególnych zmiennych.

## Odpowiedź na pytania badawcze i podsumowanie

Wykrycie obserwacji odstających:

```{r}
names(df)
zmienne <- c("Age", "Diastolic.blood.pressure")
# identify_outliers(df["Troponin"])

```

```{r}
```

GLM założenia: - Homogeneity of variance - levene test - Normality of residuals - shapiro-wilk

```{r}
tail(df[df$CK.MB>=300, ])
```

```{r}
sample <- sample(c(TRUE, FALSE), nrow(df), replace=TRUE, prob=c(0.7,0.3))
test   <- df[!sample, ]
df  <- df[sample, ]


model <- glm(Result~log(CK.MB)+log(Troponin), family = 'binomial', data = df)

summary(model)

probs <- predict(model, newdata = test, type = "response")
pred <- rep(0, length(probs))
pred[probs > .5] <- 1
table(pred, test$Result)
```

Dalex - paczka do wyjasniania modelu

```{r}
#explainer <- explain(model, data = test[-9], y = test[9])
#explainer %>% model_performance()

#explainer %>% feature_importance() %>% plot()
#explainer %>% model_performance()  %>% plot()

```

## Model drzewa decyzyjnego

### Użycie cross validation do trenowania modelu

Podział zbioru danych (90% dane treningowe i 10% dane testowe)

```{r}
podzial <- createDataPartition(y = df$Result, 
                               times = 1, 
                               p = 0.9, 
                               list = F)
train <- df[podzial, ]
test <- df[-podzial, ]
```

Trenowanie modelu z użyciem cross validation

```{r}
model <- caret::train(x= train[-9], 
                      y=train[,9], 
                      method = 'rpart', 
                      trControl = trainControl(method = 'cv', number=5))
```

Testowanie modelu i wyświetlenie tabeli pomyłek

```{r}
model_test <- predict(model, test)
model_test <- as.data.frame(model_test)

table(Rzeczywistość=test$Result, Przewidziano=model_test[,'model_test'])
```

### Używając domyślej funkcji rpart do trenowania drzewa decyzyjnego

Podział zbioru na treningowy i testowy

```{r}
podzial <- createDataPartition(y = df$Result, 
                               times = 1, 
                               p = 0.7, 
                               list = F)

train <- df[podzial, ]
test <- df[-podzial, ]
test %>% dim()
model_test$Result %>% head()
```

Trenowanie modelu

```{r}
model <- rpart(Result ~ ., method = "class", data = train)

fancyRpartPlot(model, caption = "")
```

Testowanie dokładności modelu na zbiorze testowym

```{r}
model_test <- predict(model, test)
model_test <- as.data.frame(model_test)
model_test <- model_test %>% mutate(Result = ifelse(`0` >= .5, 0, 1))

model_test$Result %>% length()

table(test$Result, model_test$Result)
```

## Modele bez zmiennych CK.MB i Troponin

```{r}
df2 <- df %>% 
  select(Age, Gender, `Heart Rate`, Systolic.blood.pressure, Diastolic.blood.pressure, Blood.sugar, Result)
```

### Drzewo decyzyjne

```{r}
podzial2 <- createDataPartition(y = df2$Result, 
                                times = 1, 
                                p = 0.7, 
                                list = F)

train2 <- df2[podzial2, ]
test2 <- df2[-podzial2, ]

model2 <- rpart(Result ~ ., method = "class", data = train2, minsplit = 100)

fancyRpartPlot(model2, caption = "")
```

Dokładność

```{r}
model_test2 <- predict(model2, test2)
model_test2 <- as.data.frame(model_test2)

model_test2 <- model_test2 %>% 
  mutate(Result = ifelse(`0` >= .5, 0, 1))

tab <- table(test2$Result, model_test2$Result)
(tab[1, 1] + tab[2, 2])/394*100
```

### Regresja logistyczna

```{r}
model3 <- glm(Result~., family = 'binomial', data = df2)

summary(model3)

probs <- predict(model3, newdata = test2, type = "response")
pred <- rep(0, length(probs))
pred[probs > .5] <- 1
table(pred, test2$Result)

explainer2 <- explain(model3, data = test2[-7], y = test[7])
explainer2 %>% model_performance()

explainer2 %>% feature_importance() %>% plot()
```

W modelu regresji logistycznej tylko dwie zmienne są statystycznie istotne (age i gender), ale nie są one wytłumaczyć czy ktoś ma zawał serca tak dobrze jak w modelu drzewa decyzyjnego.
